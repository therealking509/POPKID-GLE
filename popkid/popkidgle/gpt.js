import axios from 'axios';
import config from '../../config.cjs';

const gpt = async (m, sock) => {
  const prefix = config.PREFIX;
  const body = m.body || '';
  const isCmd = body.startsWith(prefix);
  const cmd = isCmd ? body.slice(prefix.length).split(' ')[0].toLowerCase() : '';
  const text = body.slice(prefix.length + cmd.length).trim();

  if (cmd === "gpt") {
    await sock.sendMessage(m.from, { react: { text: "ğŸ¤–", key: m.key } });

    const start = new Date().getTime();
    const uptimeSeconds = process.uptime();
    const hours = Math.floor(uptimeSeconds / 3600);
    const minutes = Math.floor((uptimeSeconds % 3600) / 60);
    const seconds = Math.floor(uptimeSeconds % 60);
    const uptime = `${hours}h ${minutes}m ${seconds}s`;

    if (!text) {
      return await sock.sendMessage(m.from, {
        text: `â“ *Please provide a question!*\nExample:\n*.gpt What is Artificial Intelligence?*`,
      }, { quoted: m });
    }

    try {
      const response = await axios.post(
        'https://api.groq.com/openai/v1/chat/completions',
        {
          model: 'meta-llama/llama-4-scout-17b-16e-instruct',
          messages: [{ role: 'user', content: text }],
          temperature: 0.7,
          max_tokens: 1000
        },
        {
          headers: {
            'Authorization': 'Bearer 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',
            'Content-Type': 'application/json'
          },
          timeout: 15000
        }
      );

      const end = new Date().getTime();
      const speed = ((end - start) / 1000).toFixed(2);
      const answer = response.data?.choices?.[0]?.message?.content?.trim();

      if (!answer) {
        return await sock.sendMessage(m.from, {
          text: `âš ï¸ I couldn't generate a valid response.`,
        }, { quoted: m });
      }

      await sock.sendMessage(m.from, {
        image: { url: 'https://i.ibb.co/NymxRZH/ai-icon.png' },
        caption:
`â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â­“
â”‚ ğŸ¤– ğ˜½ğ™¤ğ™©: *Popkid-XD*
â”‚ â±ï¸ ğ™ğ™¥ğ™©ğ™ğ™¢ğ™š: ${uptime}
â”‚ âš¡ ğ™ğ™¥ğ™šğ™šğ™™: ${speed}s
â”‚ ğŸ’¬ ğ™Œğ™ªğ™šğ™¨ğ™©ğ™ğ™¤ğ™£: *${text}*
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â­“

ğŸ§  *Answer:*
${answer}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ¤– *Powered by LLaMA 4 Scout via Groq*
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”`,
        contextInfo: {
          forwardingScore: 999,
          isForwarded: true,
          externalAdReply: {
            title: "LLaMA GPT Response",
            body: "Ask anything using .gpt",
            thumbnailUrl: "https://i.ibb.co/NymxRZH/ai-icon.png",
            sourceUrl: "https://groq.com",
            mediaType: 1,
            renderLargerThumbnail: true
          },
          forwardedNewsletterMessageInfo: {
            newsletterName: "Popkid-Xmd",
            newsletterJid: "120363290715861418@newsletter"
          }
        }
      }, { quoted: m });

    } catch (err) {
      console.error("GPT Error:", err.message);
      return await sock.sendMessage(m.from, {
        text: "ğŸš« Sorry, there was an error getting the GPT response. Please try again later.",
      }, { quoted: m });
    }
  }
};

export default gpt;
